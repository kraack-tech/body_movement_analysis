{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4281caa3-88b9-46d6-ae79-461a1460898c",
   "metadata": {},
   "source": [
    "# Body movement detection and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51b16c6-08a3-4f55-949c-38dcdf78befe",
   "metadata": {},
   "source": [
    "#### The application uses MediaPipe and OpenCV to capture video from a webcam feed to detect and analyse movement. The primary objective is to assess body movement in real time, categorise activity levels and identify the most active body parts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251c68af-2e10-4893-8d5d-dced0e362586",
   "metadata": {},
   "source": [
    "## Libraries and requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d0849b-1550-4be1-aad3-c075fdbf6b72",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2712605-79f9-498d-8ca1-a724312467e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b3ef1d-bd2a-4778-b570-f97a8d865c16",
   "metadata": {},
   "source": [
    "#### Application requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84149a10-b121-4e95-b92a-2d078367d9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 1.26.4\n",
      "opencv-python: 4.10.0\n",
      "mediapipe: 0.10.14\n"
     ]
    }
   ],
   "source": [
    "# Libraries and versions\n",
    "libraries = {\n",
    "    'numpy': np.__version__,\n",
    "    'opencv-python': cv2.__version__,\n",
    "    'mediapipe': mp.__version__,\n",
    "}\n",
    "\n",
    "# Write to the requirements file and print\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    for lib, version in libraries.items():\n",
    "        f.write(f\"{lib}=={version}\\n\")\n",
    "        print(f\"{lib}: {version}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee86f44e-91dc-4ea6-a198-ffb1e20869ad",
   "metadata": {},
   "source": [
    "### Body movement detection and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b535e1fb-01da-4c1f-bf0f-4dd0b33c132c",
   "metadata": {},
   "source": [
    "#### Functions for calculating and categorising movement for body parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a38dcf5a-0ce2-46b7-816b-d23f51e4bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze movements based on landmarks\n",
    "def calculate_movement(landmarks_curr, landsmarks_prev):\n",
    "    # Initialize dictionary for distances \n",
    "    movement = {}\n",
    "    \n",
    "    # Body parts tracked\n",
    "    body_parts = {\n",
    "        'Left Eye': (mp_pose.PoseLandmark.LEFT_EYE.value),  # Left eye landmark (used for tracking head movement)\n",
    "        'Right Eye': (mp_pose.PoseLandmark.RIGHT_EYE.value),  # Right eye landmark (used for tracking head movement)\n",
    "        #'Nose ': (mp_pose.PoseLandmark.NOSE.value),  #Nose landmark (not in use)\n",
    "        'Left Shoulder': mp_pose.PoseLandmark.LEFT_SHOULDER.value,  # Left Shoulder\n",
    "        'Right Shoulder': mp_pose.PoseLandmark.RIGHT_SHOULDER.value,  # Right Shoulder\n",
    "        'Left Elbow': mp_pose.PoseLandmark.LEFT_ELBOW.value,  # Left Elbow\n",
    "        'Right Elbow': mp_pose.PoseLandmark.RIGHT_ELBOW.value,  # Right Elbow\n",
    "        'Left Wrist': mp_pose.PoseLandmark.LEFT_WRIST.value, # Left wrist\n",
    "        'Right Wrist': mp_pose.PoseLandmark.RIGHT_WRIST.value, # Right wrist\n",
    "        'Left Hip': mp_pose.PoseLandmark.LEFT_HIP.value,  # Left Hip\n",
    "        'Right Hip': mp_pose.PoseLandmark.RIGHT_HIP.value,  # Right Hip\n",
    "        'Left Knee': mp_pose.PoseLandmark.LEFT_KNEE.value,  # Left Knee\n",
    "        'Right Knee': mp_pose.PoseLandmark.RIGHT_KNEE.value,  # Right Knee\n",
    "        'Left Ankle': mp_pose.PoseLandmark.LEFT_ANKLE.value,  # Left Ankle\n",
    "        'Right Ankle': mp_pose.PoseLandmark.RIGHT_ANKLE.value  # Right Ankle\n",
    "    }\n",
    "    \n",
    "    # Calculate movement for each tracked body part\n",
    "    for part, i in body_parts.items():\n",
    "        pos_curr = [landmarks_curr[i].x, landmarks_curr[i].y]\n",
    "        pos_prev = [landsmarks_prev[i].x, landsmarks_prev[i].y]\n",
    "        distance = np.linalg.norm(np.array(pos_curr) - np.array(pos_prev))\n",
    "        movement[part] = distance\n",
    "\n",
    "    # Return distances dictionary\n",
    "    return movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ed1280-0035-4cda-811f-f1a9175afc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize overall body movement\n",
    "def categorize_movement(total_movement):\n",
    "    if total_movement < 0.1:  # Low body movement observed during video capture (very little movement observed)\n",
    "        return \"Low\", total_movement\n",
    "    elif total_movement < 0.4:  # Medium body movement observed during video capture (regular movement observed)\n",
    "        return \"Medium\", total_movement\n",
    "    else:  # High body movement observed during video capture (excessive movement observed)\n",
    "        return \"High\", total_movement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be832f25-8b8a-41b6-95c8-28e98d455e1c",
   "metadata": {},
   "source": [
    "#### Analysing webcam capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4796201-3e61-4258-8da8-34e1dfd2c12b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movement Analysis Report:\n",
      "Overall Movement Score: 0.32\n",
      "Overall Movement Classification: Medium\n",
      "Maximum Movement Observed at: 23.20 sec\n",
      "Most Moved Body Part: Elbows\n",
      "Most Moved Body Part Score: 0.13\n",
      "Individual Movements:\n",
      "  Left Eye: 0.00\n",
      "  Right Eye: 0.00\n",
      "  Left Shoulder: 0.01\n",
      "  Right Shoulder: 0.01\n",
      "  Left Elbow: 0.12\n",
      "  Right Elbow: 0.02\n",
      "  Left Wrist: 0.03\n",
      "  Right Wrist: 0.03\n",
      "  Left Hip: 0.01\n",
      "  Right Hip: 0.01\n",
      "  Left Knee: 0.02\n",
      "  Right Knee: 0.02\n",
      "  Left Ankle: 0.03\n",
      "  Right Ankle: 0.03\n"
     ]
    }
   ],
   "source": [
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize previous landmarks and analytics storage\n",
    "landsmarks_prev = None\n",
    "\n",
    "# Initialize dictionary for movement data\n",
    "movement_data = {}\n",
    "\n",
    "# Initialize time variables for identifying time of observations\n",
    "start_time = time.time()  # Start time\n",
    "max_time = 0  # Variable for time of maximum movement\n",
    "max_movement = 0  # Variable for maximum movement score observed\n",
    "\n",
    "# Initialize video capture from webcam\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "while video.isOpened():\n",
    "    ret, image = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert image to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process image to retrieve pose landmarks\n",
    "    image_pose = pose.process(image_rgb)\n",
    "    \n",
    "    # Check if landmarks are detected\n",
    "    if image_pose.pose_landmarks:\n",
    "        # Draw detected landmarks \n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, image_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Extract current landmark\n",
    "        landmarks_curr = image_pose.pose_landmarks.landmark\n",
    "\n",
    "        # Detect and analyse body part movement obtained with the landmarks\n",
    "        if landsmarks_prev is not None:\n",
    "            # Call movement calculator function to get differrence between current and prevous landmark\n",
    "            movement = calculate_movement(landmarks_curr, landsmarks_prev)\n",
    "            movement_total = sum(movement.values())  # Total movement score\n",
    "\n",
    "            # Call movement categorizer function to obtain total movement classification score (low, med, high) \n",
    "            movement_class, _ = categorize_movement(movement_total)\n",
    "\n",
    "            # Summarize body part movement\n",
    "            movement_parts = {\n",
    "                'Head': movement['Left Eye'] + movement['Left Eye'],  # Head movement score\n",
    "                'Shoulders': movement['Left Shoulder'] + movement['Right Shoulder'],  # Shoulders movement score\n",
    "                'Hands': movement['Left Wrist'] + movement['Right Wrist'],  # Hands movement score\n",
    "                'Elbows': movement['Left Elbow'] + movement['Right Elbow'],  # Elbows movement score\n",
    "                'Hips': movement['Left Hip'] + movement['Right Hip'],  # Hips movement score\n",
    "                'Knees': movement['Left Knee'] + movement['Right Knee'],  # Knees movement score\n",
    "                'Ankles': movement['Left Ankle'] + movement['Right Ankle']  # Ankles movement score\n",
    "            }\n",
    "            \n",
    "            # Identify most moved body part\n",
    "            movement_max = max(movement_parts, key=movement_parts.get)\n",
    "\n",
    "            # Check if this is the maximum movement so far\n",
    "            current_time = time.time() - start_time\n",
    "        \n",
    "            # Check if current overall movement score is higher than the previous max observer\n",
    "            if movement_total > max_movement:\n",
    "                max_movement = movement_total  # Update if new max is observed\n",
    "                max_time = current_time  # Update obervation time\n",
    "\n",
    "            # Display overall movement classification score on video capture\n",
    "            cv2.putText(\n",
    "                image, f'Movement: {movement_class}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "            # Display time of maximum movement observed\n",
    "            cv2.putText(\n",
    "                image, f'Max Movement at: {max_time:.2f} sec', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA\n",
    "            )\n",
    "\n",
    "            # Store the movement data to the dictionary \n",
    "            movement_data['total_movement'] = movement_total  # Overall movement score (i.e. sum of movement values)\n",
    "            movement_data['total_movement_class'] = movement_class  # Overall movement classification\n",
    "            movement_data['most_moved_part'] = movement_max  # Most moved body part class\n",
    "            movement_data['most_moved_score'] = movement_parts[movement_max]  # Most moved body part score\n",
    "            movement_data['individual_movements'] = movement  # Individual body part scores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Update previous landmarks\n",
    "        landsmarks_prev = landmarks_curr\n",
    "\n",
    "    # Display image with landmarks\n",
    "    cv2.imshow('Pose Estimation & Movement Analysis', image)\n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all OpenCV windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Print the analytical report after closing the video capture\n",
    "print(\"Movement Analysis Report:\") \n",
    "print(f\"Overall Movement Score: {movement_data.get('total_movement', 0):.2f}\")  # Overall score\n",
    "print(f\"Overall Movement Classification: {movement_data.get('total_movement_class', 'N/A')}\") # Overall classification\n",
    "print(f'Maximum Movement Observed at: {max_time:.2f} sec')\n",
    "print(f\"Most Moved Body Part: {movement_data.get('most_moved_part', 'N/A')}\")  # Most moved body part class\n",
    "print(f\"Most Moved Body Part Score: {movement_data.get('most_moved_score', 0):.2f}\")  # Most moved body part score\n",
    "# All individual body part scores observed\n",
    "print(\"Individual Movements:\") \n",
    "for part, movement in movement_data.get('individual_movements', {}).items():\n",
    "    print(f\"  {part}: {movement:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aad2b5-a2ff-4b2f-b3f1-2b0ee0089f50",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a5ef7f-6309-4bfb-a4a1-a4b63c49745a",
   "metadata": {},
   "source": [
    "The application effectively tracks body part movements and generates analytics, including which body part is the most active, the overall movement classification, and the specific timepoints of heightened activity. While the insights from movement analysis alone may not yield significant meaning, when combined with other emotional recognition tools—such as Voice Tone Analysis (emotion detection from audio), Semantic Analysis of Spoken Words (using NLP), and Facial Expression Analysis (emotion detection through facial features)—the application can provide valuable insights into body language during critical moments. This multifaceted approach enhances the understanding of emotional and behavioral patterns, making it a useful too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f46399-d820-487c-823e-b2a6e03a83cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow GPU Kernel",
   "language": "python",
   "name": "tensor-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
